import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import r2_score
from sklearn.covariance import EllipticEnvelope
plt.rcParams['font.family'] = 'Malgun Gothic'

# 1. ë°ì´í„° ë¡œë“œ
path = './_data/dacon/ë”°ë¦‰ì´/'
train_csv = pd.read_csv(path + 'train.csv', index_col=0)
test_csv = pd.read_csv(path + 'test.csv', index_col=0)
submission_csv = pd.read_csv(path + 'submission.csv', index_col=0)

train_csv = train_csv.dropna()
test_csv = test_csv.fillna(test_csv.mean())

x = train_csv.drop(['count'], axis=1)
y = train_csv['count']
feature_names = x.columns.tolist()

# 2. ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜ (EllipticEnvelope)
def remove_outliers_elliptic(x, y, contamination=0.1):
    # ìŠ¤ì¼€ì¼ë§ (EllipticEnvelopeì€ ìŠ¤ì¼€ì¼ ë¯¼ê°)
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x)

    envelope = EllipticEnvelope(contamination=contamination, random_state=42)
    envelope.fit(x_scaled)
    results = envelope.predict(x_scaled)

    mask = results == 1  # ì •ìƒê°’ì€ 1, ì´ìƒì¹˜ëŠ” -1
    return x[mask], y[mask]

# 3. ê³µí†µ í›ˆë ¨ í•¨ìˆ˜
def train_and_evaluate_model(x, y, label=""):
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x)
    pf = PolynomialFeatures(degree=2, include_bias=False)
    x_pf = pf.fit_transform(x_scaled)

    x_train, x_test, y_train, y_test = train_test_split(
        x_pf, y, train_size=0.8, random_state=123
    )

    models = {
        "LinearRegression": LinearRegression(),
        "Ridge": Ridge(alpha=1.0),
        "Lasso": Lasso(alpha=0.1, max_iter=10000),
        "ElasticNet": ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)
    }

    r2_scores = {}
    for name, model in models.items():
        model.fit(x_train, y_train)
        y_pred = model.predict(x_test)
        r2 = r2_score(y_test, y_pred)
        r2_scores[f"{name} {label}"] = r2
        print(f"{name} {label} RÂ² score: {round(r2, 4)}")
    return r2_scores

# 4. ì´ìƒì¹˜ ì œê±° ì „
print("\nğŸ“Œ ì´ìƒì¹˜ ì œê±° ì „ ì„±ëŠ¥:")
r2_before = train_and_evaluate_model(x, y, label="(Before)")

# 5. ì´ìƒì¹˜ ì œê±° í›„ (EllipticEnvelope)
x_clean, y_clean = remove_outliers_elliptic(x, y, contamination=0.1)
print("\nğŸ“Œ ì´ìƒì¹˜ ì œê±° í›„ ì„±ëŠ¥ (EllipticEnvelope):")
r2_after = train_and_evaluate_model(x_clean, y_clean, label="(After)")

# 6. ì‹œê°í™”
r2_scores = {**r2_before, **r2_after}
plt.figure(figsize=(12, 6))
colors = ['skyblue' if 'Before' in name else 'lightgreen' for name in r2_scores.keys()]
plt.bar(r2_scores.keys(), r2_scores.values(), color=colors)
plt.ylabel("RÂ² score")
plt.title("ì´ìƒì¹˜ ì œê±° ì „ vs í›„ - íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ (EllipticEnvelope)")
plt.ylim(0.1, 0.85)
plt.xticks(rotation=45)
for i, (name, value) in enumerate(r2_scores.items()):
    plt.text(i, value + 0.005, f"{value:.4f}", ha='center', va='bottom', fontsize=9)
plt.grid(axis='y')
plt.tight_layout()
plt.show()


# ğŸ“Œ ì´ìƒì¹˜ ì œê±° ì „ ì„±ëŠ¥:
# LinearRegression (Before) RÂ² score: 0.5692
# Ridge (Before) RÂ² score: 0.578
# Lasso (Before) RÂ² score: 0.585
# ElasticNet (Before) RÂ² score: 0.5828

# ğŸ“Œ ì´ìƒì¹˜ ì œê±° í›„ ì„±ëŠ¥ (EllipticEnvelope):
# LinearRegression (After) RÂ² score: 0.3646
# Ridge (After) RÂ² score: 0.3853
# Lasso (After) RÂ² score: 0.3868
# ElasticNet (After) RÂ² score: 0.3943