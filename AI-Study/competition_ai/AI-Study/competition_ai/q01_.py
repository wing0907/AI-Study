import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
from sklearn.metrics import accuracy_score
import pandas as pd
from datetime import datetime
import pennylane as qml

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) ê²½ë¡œ, Seed, Device ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Windows ê²½ë¡œ ì•ˆì „í•˜ê²Œ
base_path = r'C:\Study25\\competition_ai\\'
os.makedirs(base_path, exist_ok=True)

SEED = 907
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì„¤ì •ê°’
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
n_qubits           = 5
q_layers           = 3
batch_size         = 64
learning_rate      = 7e-4
weight_decay       = 5e-4
dropout_rate       = 0.5
label_smoothing    = 0.05
cutmix_mixup_prob  = 0.2            # 20% í™•ë¥ ë¡œ CutMix/MixUp ì ìš©
cutmix_or_mixup    = 'mixup'        # 'cutmix' ë˜ëŠ” 'mixup'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ë°ì´í„° ì¤€ë¹„ (+ 0 vs 6 í•„í„° & 6->1 ë§¤í•‘)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_full = datasets.FashionMNIST(root=base_path, train=True,  download=True, transform=transform_train)
test_full  = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)

idx_tr = [i for i,(_,l) in enumerate(train_full) if l in (0,6)]
idx_te = [i for i,(_,l) in enumerate(test_full)  if l in (0,6)]
train_ds = Subset(train_full, idx_tr)
test_ds  = Subset(test_full,  idx_te)

# 6 -> 1 ë§¤í•‘
for ds in (train_ds, test_ds):
    t = ds.dataset.targets
    t[t == 6] = 1

train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
eval_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) Label Smoothing + CutMix/MixUp
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes=2, smoothing=0.03):
        super().__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.cls = classes

    def forward(self, pred, target):
        pred = pred.log_softmax(dim=-1)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.cls - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        return torch.mean(torch.sum(-true_dist * pred, dim=-1))

def mixup_data(x, y, alpha=1.0):
    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0
    batch = x.size(0)
    index = torch.randperm(batch).to(x.device)
    mixed_x = lam * x + (1 - lam) * x[index]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def cutmix_data(x, y, alpha=1.0):
    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0
    b, _, h, w = x.size()
    index = torch.randperm(b).to(x.device)
    y_a, y_b = y, y[index]
    cx, cy   = np.random.randint(w), np.random.randint(h)
    cut_w    = int(w * np.sqrt(1 - lam))
    cut_h    = int(h * np.sqrt(1 - lam))
    x1 = np.clip(cx - cut_w // 2, 0, w)
    x2 = np.clip(cx + cut_w // 2, 0, w)
    y1 = np.clip(cy - cut_h // 2, 0, h)
    y2 = np.clip(cy + cut_h // 2, 0, h)
    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]
    lam = 1 - ((x2 - x1) * (y2 - y1) / (w * h))
    return x, y_a, y_b, lam

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) QNode (PennyLane)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def qnode_template(n_qubits, n_layers):
    dev = qml.device("default.qubit", wires=n_qubits)
    @qml.qnode(dev, interface="torch")
    def circuit(x, weights):
        # x: [B, n_qubits]
        # ì…ë ¥ ì¸ì½”ë”©
        for i in range(n_qubits):
            qml.RX(x[:, i], wires=i)
        # ì¸µ ë°˜ë³µ
        for l in range(n_layers):
            for i in range(n_qubits):
                qml.RY(weights[l, i, 0], wires=i)
                qml.RZ(weights[l, i, 1], wires=i)
            # CZ ë§ ì»¤ë„¥ì…˜
            for i in range(n_qubits):
                qml.CZ(wires=[i, (i+1) % n_qubits])
        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]
    return circuit

quantum_circuit = qnode_template(n_qubits, q_layers)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class HybridModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, padding=1); self.bn1 = nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16,32, 3, padding=1); self.bn2 = nn.BatchNorm2d(32)
        self.conv3 = nn.Conv2d(32,64, 3, padding=1); self.bn3 = nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64,32, 3, padding=1); self.bn4 = nn.BatchNorm2d(32)
        self.pool  = nn.MaxPool2d(2, 2)
        self.drop  = nn.Dropout(dropout_rate)
        self.avg   = nn.AdaptiveAvgPool2d((1, 1))

        self.fc1   = nn.Linear(32, n_qubits)
        self.norm  = nn.LayerNorm(n_qubits)
        self.qp    = nn.Parameter(torch.randn(q_layers, n_qubits, 2))

        self.fc2   = nn.Linear(n_qubits, 32)
        self.fc3   = nn.Linear(32, 2)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x))); x = self.pool(x)
        x = F.relu(self.bn2(self.conv2(x))); x = self.pool(x)
        x = F.relu(self.bn3(self.conv3(x))); x = self.pool(x)
        x = F.relu(self.bn4(self.conv4(x))); x = self.pool(x)
        x = self.drop(x)
        x = self.avg(x).view(x.size(0), -1)

        x = self.fc1(x)
        x = self.norm(x)
        x = torch.tanh(x)  # ì•ˆì •í™”

        q_out = quantum_circuit(x, self.qp)
        q_out = torch.stack(q_out, dim=1).float()  # [B, n_qubits]

        x = F.relu(self.fc2(q_out))
        return F.log_softmax(self.fc3(x), dim=1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) ìŠ¤í™ ê²€ì‚¬(ëŒ€íšŒ ê·œì • ì²´í¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with torch.no_grad():
    spec_model = HybridModel().to(device).eval()
    dummy_x = torch.randn(1, n_qubits)
    dummy_w = spec_model.qp.data
    specs = qml.specs(quantum_circuit)(dummy_x, dummy_w)
    assert specs["num_tape_wires"] <= 8,  "âŒ íë¹— ìˆ˜ ì´ˆê³¼"
    assert specs["resources"].depth <= 30, "âŒ íšŒë¡œ ê¹Šì´ ì´ˆê³¼"
    assert specs["num_trainable_params"] <= 60, "âŒ í•™ìŠµ í€€í…€ íŒŒë¼ë¯¸í„° ìˆ˜ ì´ˆê³¼"

    total_params = sum(p.numel() for p in spec_model.parameters() if p.requires_grad)
    assert total_params <= 50000, "âŒ í•™ìŠµ ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜ ì´ˆê³¼"
    print("âœ… QNN spec OK")
    print(f"âœ… Total params: {total_params}")
    del spec_model

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) í•™ìŠµ ì¤€ë¹„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model     = HybridModel().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)  # verbose ì œê±°
criterion = LabelSmoothingLoss(classes=2, smoothing=label_smoothing)

best_acc   = 0.0
no_improve = 0
patience   = 50
best_path  = os.path.join(base_path, 'best_model.pth')

epochs = 500
for ep in range(1, epochs+1):
    model.train()
    loss_sum, corr, tot = 0.0, 0, 0

    for imgs, lbls in train_loader:
        imgs, lbls = imgs.to(device), lbls.to(device)
        optimizer.zero_grad()

        if np.random.rand() < cutmix_mixup_prob:
            if cutmix_or_mixup == 'cutmix':
                imgs_mix, targets_a, targets_b, lam = cutmix_data(imgs, lbls)
            elif cutmix_or_mixup == 'mixup':
                imgs_mix, targets_a, targets_b, lam = mixup_data(imgs, lbls)
            else:
                raise ValueError("cutmix_or_mixup must be 'cutmix' or 'mixup'")

            outputs = model(imgs_mix)
            loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)
        else:
            outputs = model(imgs)
            loss = criterion(outputs, lbls)

        loss.backward()
        optimizer.step()

        loss_sum += loss.item()
        preds = outputs.argmax(1)
        corr += (preds == lbls).sum().item()
        tot  += lbls.size(0)

    train_acc  = corr / tot * 100.0
    train_loss = loss_sum / len(train_loader)

    # ìŠ¤ì¼€ì¤„ëŸ¬(ê°ì†Œì‹œë§Œ ë¡œê·¸)
    old_lr = optimizer.param_groups[0]["lr"]
    scheduler.step(train_loss)
    new_lr = optimizer.param_groups[0]["lr"]
    if new_lr != old_lr:
        print(f"[Scheduler] LR reduced: {old_lr:.6f} -> {new_lr:.6f}")

    print(f"Epoch {ep}/{epochs}  Loss: {train_loss:.4f}  Acc: {train_acc:.2f}%")

    # âœ… ìµœê³  ì •í™•ë„ ê°±ì‹ ì‹œì—ë§Œ ì €ì¥
    if train_acc > best_acc:
        best_acc = train_acc
        no_improve = 0
        torch.save(model.state_dict(), best_path)
        print(f"  â¡ï¸ New best (Train Acc): {best_acc:.2f}%  |  Saved: {best_path}")
    else:
        no_improve += 1
        if no_improve >= patience:
            print("  â¹ Early stopping (no improvement).")
            break

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) í‰ê°€ & ì œì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìµœê³  ì„±ëŠ¥ ì‹œì  ëª¨ë¸ ë¡œë“œ
model.load_state_dict(torch.load(best_path, map_location=device))
print(f"\nâœ… Loaded best model from: {best_path}")
print(f"âœ… Best Train Accuracy (during training): {best_acc:.2f}%")

# Eval set ìµœì¢… accuracy ì¶œë ¥
model.eval()
corr, tot = 0, 0
with torch.no_grad():
    for imgs, lbls in eval_loader:
        imgs, lbls = imgs.to(device), lbls.to(device)
        preds = model(imgs).argmax(1)
        corr += (preds == lbls).sum().item()
        tot  += lbls.size(0)
final_acc = corr / tot * 100.0
print(f"ğŸ Final Accuracy on Eval set: {final_acc:.2f}%")

# ì œì¶œ CSV
all_preds = []
with torch.no_grad():
    for imgs, _ in test_loader:
        imgs = imgs.to(device)
        all_preds.extend(model(imgs).argmax(1).cpu().numpy())

sub = [0 if p == 0 else 6 for p in all_preds]
now = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_path = os.path.join(base_path, f"submission_{now}.csv")
pd.DataFrame({"y_pred": sub}).to_csv(csv_path, index=False, header=False)
print(f"âœ… Saved submission: {csv_path}")
