import multiprocessing
import pennylane as qml
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import numpy as np
import pandas as pd
from datetime import datetime
import os
import random

# ------------------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ì„ ì–¸: Windowsì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ì•ˆì •ì„±ì„ ìœ„í•´
# __name__ == '__main__' ë¸”ë¡ì´ ìµœìƒë‹¨ì— ì˜¤ëŠ” ê²ƒì„ ê¶Œì¥í•˜ëŠ” ê²½ìš°ë„ ìˆìœ¼ë‚˜,
# ìŠ¤í¬ë¦½íŠ¸ì˜ ê°€ë…ì„±ì„ ìœ„í•´ í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ì˜ í›„ ë©”ì¸ ë¡œì§ì„ ë°°ì¹˜í•©ë‹ˆë‹¤.
# ------------------------------------------------------------------------------------

##############################
# 0ï¸âƒ£ ê²½ë¡œ ì„¤ì •
##############################
base_path = './Study25/_data/quantum/'
os.makedirs(base_path, exist_ok=True)

##############################
# 1ï¸âƒ£ Seed ê³ ì •
##############################
SEED = 222
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
# if torch.cuda.is_available():
#     torch.cuda.manual_seed(SEED)
#     torch.cuda.manual_seed_all(SEED)
#     torch.backends.cudnn.deterministic = True
#     torch.backends.cudnn.benchmark = False

# âœ¨ ìˆ˜ì • ì œì•ˆ
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    # ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©ì„ ë¹„í™œì„±í™”í•˜ì—¬ ìœ ì—°ì„± ë¶€ì—¬
    torch.backends.cudnn.deterministic = False
    # cuDNNì´ ê°€ì¥ ì í•©í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì°¾ë„ë¡ í—ˆìš©
    torch.backends.cudnn.benchmark = True
    
##############################
# 2ï¸âƒ£ ë””ë°”ì´ìŠ¤ ì„ ì–¸
##############################
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 5ê°œì˜ íë¹„íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ì–‘ì ë””ë°”ì´ìŠ¤ ì„ ì–¸
dev = qml.device("default.qubit", wires=5)

##############################
# 3ï¸âƒ£ QNN íšŒë¡œ ì •ì˜
##############################
@qml.qnode(dev, interface="torch")
def quantum_circuit(inputs, weights):
    num_qubits = 5
    layers = 2

    # ì…ë ¥ ë°ì´í„°(inputs)ì™€ ê°€ì¤‘ì¹˜(weights)ë¥¼ ì¸ì½”ë”©
    for l in range(layers):
        for i in range(num_qubits):
            # ì…ë ¥ ë°ì´í„°ëŠ” ë°°ì¹˜ í˜•íƒœë¡œ ë“¤ì–´ì˜´ (batch_size, num_inputs)
            # PennyLaneì´ ìë™ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì›ì„ ì²˜ë¦¬í•´ì¤Œ
            qml.RX(inputs[:, i % inputs.shape[1]], wires=i)
            qml.RY(weights[(l * num_qubits + i) % weights.shape[0]], wires=i)

        for i in range(num_qubits - 1):
            qml.CNOT(wires=[i, i+1])
        qml.CNOT(wires=[num_qubits - 1, 0])

    # RZëŠ” ë§ˆì§€ë§‰ì— í•œ ë²ˆë§Œ ì ìš©
    for i in range(num_qubits):
        qml.RZ(weights[(i + weights.shape[0] // 2) % weights.shape[0]], wires=i)
    
    # âœ¨ ê°œì„  ì‚¬í•­: ê° íë¹„íŠ¸ì˜ ê¸°ëŒ“ê°’ì„ ëª¨ë‘ ì¸¡ì •í•˜ì—¬ ë‹¤ì¤‘ ì¶œë ¥ ìƒì„±
    # [qml.expval(qml.PauliZ(0) @ qml.PauliZ(1))] ëŒ€ì‹  ì•„ë˜ ì½”ë“œë¥¼ ì‚¬ìš©
    return [qml.expval(qml.PauliZ(i)) for i in range(num_qubits)]

##############################
# 4ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ (Dataset ì •ì˜)
##############################
transform_train = transforms.Compose([
    transforms.RandomRotation(15),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset_full = datasets.FashionMNIST(root=base_path, train=True, download=True, transform=transform_train)
test_dataset_full = datasets.FashionMNIST(root=base_path, train=False, download=True, transform=transform_test)

# í´ë˜ìŠ¤ 0, 6 ë°ì´í„° í•„í„°ë§ ë° ë ˆì´ë¸” ë³€í™˜ (0 -> 0, 6 -> 1)
indices_train = [i for i, (_, label) in enumerate(train_dataset_full) if label in [0, 6]]
train_dataset = Subset(train_dataset_full, indices_train)
for i in range(len(train_dataset.dataset.targets)):
    if train_dataset.dataset.targets[i] == 6:
        train_dataset.dataset.targets[i] = 1

indices_test = [i for i, (_, label) in enumerate(test_dataset_full) if label in [0, 6]]
test_subset = Subset(test_dataset_full, indices_test)
for i in range(len(test_subset.dataset.targets)):
    if test_subset.dataset.targets[i] == 6:
        test_subset.dataset.targets[i] = 1

##############################
# 5ï¸âƒ£ ëª¨ë¸ ì •ì˜
##############################
class HybridModel(nn.Module):
    def __init__(self):
        super().__init__()
        # í´ë˜ì‹ CNN ë¶€ë¶„
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.bn1 = nn.BatchNorm2d(16)
        self.bn2 = nn.BatchNorm2d(32)
        self.bn3 = nn.BatchNorm2d(64)
        self.dropout = nn.Dropout(0.3)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc1 = nn.Linear(64, 5)  # âœ¨ ê°œì„  ì‚¬í•­: QNN ì…ë ¥ íë¹„íŠ¸ ìˆ˜ì™€ ë§ì¶¤ (5ê°œ)
        self.norm = nn.LayerNorm(5) 
        
        # ì–‘ì QNN ë¶€ë¶„
        self.q_params = nn.Parameter(torch.rand(30)) # ì–‘ì íšŒë¡œ ê°€ì¤‘ì¹˜
        
        # QNN ì¶œë ¥ ì´í›„ í´ë˜ì‹ ë ˆì´ì–´
        # âœ¨ ê°œì„  ì‚¬í•­: QNN ì¶œë ¥ì´ 5ê°œì´ë¯€ë¡œ ì…ë ¥ ì°¨ì›ì„ 5ë¡œ ë³€ê²½
        self.fc2 = nn.Linear(5, 32)
        self.fc3 = nn.Linear(32, 2) # ìµœì¢… 2ê°œ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜

    def forward(self, x):
        # í´ë˜ì‹ CNN íŠ¹ì§• ì¶”ì¶œ
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.pool(x)
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.pool(x)
        x = self.dropout(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.norm(x)
        
        # âœ¨ ê°œì„  ì‚¬í•­: ì–‘ì íšŒë¡œì— ë°°ì¹˜ ì „ì²´ë¥¼ í•œ ë²ˆì— ì „ë‹¬í•˜ì—¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
        q_out = quantum_circuit(x, self.q_params)
        # PennyLane ì¶œë ¥ì´ íŠœí”Œì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í…ì„œë¡œ ë³€í™˜
        q_out = torch.stack(list(q_out), dim=1).to(torch.float32)

        # ìµœì¢… ë¶„ë¥˜
        x = self.fc2(q_out)
        x = self.fc3(x)
        return F.log_softmax(x, dim=1)

# ------------------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ------------------------------------------------------------------------------------
if __name__ == '__main__':
    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹ ì„¤ì • (Windows í˜¸í™˜ì„±)
    # multiprocessing.set_start_method('spawn', force=True)

    # 4ï¸âƒ£-2. ë°ì´í„° ë¡œë” ì •ì˜
    # num_workersëŠ” í™˜ê²½ì— ë§ê²Œ ì¡°ì ˆ (0ìœ¼ë¡œ ì„¤ì • ì‹œ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì²˜ë¦¬)
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)
    test_loader = DataLoader(test_dataset_full, batch_size=64, shuffle=False, num_workers=0, pin_memory=True) 
    test_eval_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)

    # 6ï¸âƒ£ ê·œê²© ê²€ì‚¬
    model_for_specs = HybridModel()
    model_for_specs.eval()
    # âœ¨ ê°œì„  ì‚¬í•­: QNN ì…ë ¥ ì°¨ì›ì„ 5ë¡œ ë³€ê²½
    dummy_q_inputs = torch.randn(1, 5) 
    dummy_q_weights = model_for_specs.q_params.data
    q_specs = qml.specs(quantum_circuit)(dummy_q_inputs, dummy_q_weights)
    assert q_specs["num_tape_wires"] <= 8
    assert q_specs['resources'].depth <= 30
    assert q_specs["num_trainable_params"] <= 60
    print("âœ… QNN ê·œê²© ê²€ì‚¬ í†µê³¼")

    total_params = sum(p.numel() for p in model_for_specs.parameters() if p.requires_grad)
    assert total_params <= 50000
    print(f"âœ… í•™ìŠµ ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜ ê²€ì‚¬ í†µê³¼: {total_params}")
    del model_for_specs

    # 7ï¸âƒ£ í•™ìŠµ
    model = HybridModel().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=7, factor=0.5)
    criterion = nn.NLLLoss()
    best_acc = 0.0
    early_stopping_patience = 5
    epochs_no_improve = 0
    best_model_path = os.path.join(base_path, 'best_model_improved.pth') # íŒŒì¼ëª… ë³€ê²½

    epochs = 50
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            output = model(images)
            loss = criterion(output, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            preds = output.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        avg_loss = total_loss / len(train_loader)
        avg_acc = correct / total * 100
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Train Acc: {avg_acc:.2f}%")

        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(avg_acc)
        new_lr = optimizer.param_groups[0]['lr']
        if new_lr < old_lr:
            print(f"ğŸ”½ í•™ìŠµë¥  ê°ì†Œ: {old_lr:.6f} â†’ {new_lr:.6f}")

        if avg_acc > best_acc:
            best_acc = avg_acc
            epochs_no_improve = 0
            torch.save(model.state_dict(), best_model_path)
            print(f"âœ… Best model updated at epoch {epoch+1} with train acc {avg_acc:.2f}%")
        else:
            epochs_no_improve += 1
            print(f"No improvement for {epochs_no_improve} epochs.")
            if epochs_no_improve >= early_stopping_patience:
                print(f"Early stopping triggered at epoch {epoch+1}.")
                break

    # 8ï¸âƒ£ ëª¨ë¸ ì €ì¥
    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = os.path.join(base_path, f'model_{now}_final_train_acc_{best_acc:.4f}_improved.pth')
    if os.path.exists(best_model_path):
        torch.save(torch.load(best_model_path), model_path)
    else:
        torch.save(model.state_dict(), model_path)
    print(f"âœ… ë§ˆì§€ë§‰ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

    # 9ï¸âƒ£ ì¶”ë¡  ë° ì œì¶œ ìƒì„±
    if os.path.exists(best_model_path):
        model.load_state_dict(torch.load(best_model_path))
    model.eval()
    all_preds = []
    correct_eval = 0
    total_eval = 0

    with torch.no_grad():
        for images, _ in test_loader:
            images = images.to(device)
            output = model(images)
            pred = output.argmax(dim=1)
            all_preds.extend(pred.cpu().numpy())

    with torch.no_grad():
        for images, labels in test_eval_loader:
            images, labels = images.to(device), labels.to(device)
            output = model(images)
            pred = output.argmax(dim=1)
            correct_eval += (pred == labels).sum().item()
            total_eval += labels.size(0)

    eval_acc = (correct_eval / total_eval) * 100 if total_eval > 0 else 0
    print(f"\nâœ… 0/6 í´ë˜ìŠ¤ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {eval_acc:.2f}%")

    final_submission_preds = [0 if p == 0 else 6 for p in all_preds]
    csv_filename = f"{base_path}y_pred_{now}_improved.csv"
    df = pd.DataFrame({"y_pred": final_submission_preds})
    df.to_csv(csv_filename, index=False, header=False)
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")