import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors
from rdkit.Chem import rdMolDescriptors
from rdkit.Chem import Crippen
from rdkit.Chem import Lipinski
from rdkit.Chem import AllChem
from rdkit import RDLogger
from sklearn.model_selection import KFold, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout,BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau
from tensorflow.keras.models import load_model
from keras.optimizers import Adam, SGD, RMSprop
import joblib
import random
import datetime
import os
import matplotlib.pyplot as plt
import keras.backend as K
from sklearn.utils import class_weight
# ê²½ê³  ë©”ì‹œì§€ ì œê±°
RDLogger.DisableLog('rdApp.*')

# ì„¤ì •
seed = 357
random.seed(seed)
np.random.seed(seed)

# ê²½ë¡œ ì„¤ì •
path = 'C:/Study25/_data/dacon/boost_up/'
train = pd.read_csv(path + "train.csv")
test = pd.read_csv(path + "test.csv")

# SMARTS ê¸°ë°˜ ê¸°ëŠ¥ì„± ê·¸ë£¹
phenol_group = Chem.MolFromSmarts("c[OH]")
alcohol_group = Chem.MolFromSmarts("[CX4][OH]")
ketone_group = Chem.MolFromSmarts("[CX3](=O)[#6]")
thiol_ether = Chem.MolFromSmarts("[#6]-S-[#6]")
aromatic_thiol_ether = Chem.MolFromSmarts("c-S-[#6]")
sulfonyl_group = Chem.MolFromSmarts("S(=O)(=O)")
phosphates_group = Chem.MolFromSmiles("P(=O)")
amide_group = Chem.MolFromSmarts("[NX3][CX3](=O)[#6]")

# í”¼ì²˜ ìƒì„± í•¨ìˆ˜

def rdkit_features(df):
    mols = df['Canonical_Smiles'].apply(Chem.MolFromSmiles)
    df = df.copy()
    df['Mol'] = mols
    df['MolLogP'] = mols.apply(Crippen.MolLogP)
    df['NumHAcceptors'] = mols.apply(Lipinski.NumHAcceptors)
    df['NumHDonors'] = mols.apply(Lipinski.NumHDonors)
    df['TPSA'] = mols.apply(Descriptors.TPSA)
    df['NumAromaticRings'] = mols.apply(Lipinski.NumAromaticRings)
    df['NumAromaticHeterocycles'] = mols.apply(Lipinski.NumAromaticHeterocycles)
    df['NumSaturatedHeterocycles'] = mols.apply(Lipinski.NumSaturatedHeterocycles)
    df['NOCount'] = mols.apply(Descriptors.NOCount)
    df['NumRadicalElectrons'] = mols.apply(Descriptors.NumRadicalElectrons)
    df['NHOHCount'] = mols.apply(Descriptors.NHOHCount)

    # SMARTS ê¸°ë°˜ ê¸°ëŠ¥ì„± ê·¸ë£¹
    df['HasPhenol'] = mols.apply(lambda m: m.HasSubstructMatch(phenol_group)).astype(int)
    df['HasAlcohol'] = mols.apply(lambda m: m.HasSubstructMatch(alcohol_group)).astype(int)
    df['HasKetone'] = mols.apply(lambda m: m.HasSubstructMatch(ketone_group)).astype(int)
    df['HasThioether'] = mols.apply(lambda m: m.HasSubstructMatch(thiol_ether)).astype(int)
    df['HasArylThioether'] = mols.apply(lambda m: m.HasSubstructMatch(aromatic_thiol_ether)).astype(int)
    df['HasSulfonyl'] = mols.apply(lambda m: m.HasSubstructMatch(sulfonyl_group)).astype(int)
    df['HasPhosphate'] = mols.apply(lambda m: m.HasSubstructMatch(phosphates_group)).astype(int)
    df['HasAmide'] = mols.apply(lambda m: m.HasSubstructMatch(amide_group)).astype(int)

    return df

train = rdkit_features(train)
test = rdkit_features(test)

feature_cols = [col for col in train.columns if col not in ['ID', 'Canonical_Smiles', 'Inhibition', 'Mol']]
X = train[feature_cols]
y = train['Inhibition']
test_ids = test['ID'].copy()  # ğŸ”º ID ë°±ì—…
test = test[feature_cols]
# ë¡œê·¸ ë³€í™˜
y_log = np.log1p(y)

cols = ['NumHDonors','TPSA','NumRadicalElectrons']

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X[cols])
test_scaled = scaler.transform(test[cols])



# ë°ì´í„° ë¶„í• 
X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_log, test_size=0.1, random_state=seed)

# RMSE ì†ì‹¤ í•¨ìˆ˜ ì •ì˜
def rmse(y_true, y_pred):
    return K.sqrt(K.mean(K.square(y_pred - y_true)))

# DNN ëª¨ë¸ ì •ì˜
def build_model(input_dim, optimizer):
    model = Sequential()
    model.add(Dense(64, activation='relu', input_dim=input_dim))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))
    model.add(Dense(32, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.2))
    model.add(Dense(16, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))
    model.add(Dense(1))
    model.compile(optimizer=optimizer, loss=rmse, metrics=['mae'])
    return model

# ì˜µí‹°ë§ˆì´ì € ì„ íƒ ë¦¬ìŠ¤íŠ¸
optimizers = [Adam(learning_rate=0.001), SGD(learning_rate=0.01), RMSprop(learning_rate=0.001)]

# KFold Cross Validation ì„¤ì •
n_splits = 5  # í´ë“œ ìˆ˜ (5-Fold Cross Validation)
kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)

# ì½œë°± ì„¤ì •
now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
model_path = path + f'dnn_model_{now}.h5'
callbacks = [
    EarlyStopping(monitor='val_loss', patience=80, restore_best_weights=True),
    ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss'),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=1e-6)  # learning rate ìŠ¤ì¼€ì¤„ë§ ì¶”ê°€
]

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights = dict(enumerate(weights))




# K-Fold Cross Validation ì‹¤í–‰
for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled, y_log)):
    print(f"\nTraining fold {fold + 1}/{n_splits}...")

    # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
    X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]
    y_train_fold, y_val_fold = y_log[train_idx], y_log[val_idx]

    # ì˜µí‹°ë§ˆì´ì € ì„ íƒ
    optimizer = optimizers[fold % len(optimizers)]  # ê° í´ë“œë§ˆë‹¤ ë‹¤ë¥¸ ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©

    # ëª¨ë¸ ìƒì„±
    model = build_model(X_scaled.shape[1], optimizer)

    # ëª¨ë¸ í•™ìŠµ
    history = model.fit(
        X_train_fold, y_train_fold,
        validation_data=(X_val_fold, y_val_fold),
        epochs=1000,
        batch_size=4,
        callbacks=callbacks,
        verbose=1,
        class_weight=class_weights
    )

# ëª¨ë¸ ì €ì¥
model.save(model_path)
print(f"DNN ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

# ì˜ˆì¸¡ ë° í‰ê°€
pred_train_log = model.predict(X_train)
pred_val_log = model.predict(X_val)
train_preds = np.expm1(pred_train_log).flatten()
val_preds = np.expm1(pred_val_log).flatten()
y_train_orig = np.expm1(y_train)
y_val_orig = np.expm1(y_val)

train_r2 = r2_score(y_train_orig, train_preds)
val_r2 = r2_score(y_val_orig, val_preds)
train_rmse = np.sqrt(mean_squared_error(y_train_orig, train_preds))
val_rmse = np.sqrt(mean_squared_error(y_val_orig, val_preds))
train_mae = mean_absolute_error(y_train_orig, train_preds)
val_mae = mean_absolute_error(y_val_orig, val_preds)

print(f"Train RÂ² Score: {train_r2:.4f}, RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}")
print(f"Test  RÂ² Score: {val_r2:.4f}, RMSE: {val_rmse:.4f}, MAE: {val_mae:.4f}")

# í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ë° ì œì¶œ ìƒì„±
test_pred_log = model.predict(test_scaled)
test_preds = np.expm1(test_pred_log)

submission = pd.DataFrame({
    'ID': test_ids,
    'Inhibition': test_preds.flatten()
})

csv_path = path + f'submission_dnn_{now}.csv'
submission.to_csv(csv_path, index=False)
print(f"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")

# í•™ìŠµ ì‹œê°í™”
plt.figure(figsize=(10,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('DNN Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid()
plt.show()

# Train RÂ² Score: -0.1583, RMSE: 28.3781, MAE: 22.3283
# Test  RÂ² Score: -0.0954, RMSE: 27.9028, MAE: 22.0452
# 4/4 [==============================] - 0s 0s/step
# ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: C:/Study25/_data/dacon/boost_up/submission_dnn_20250716_103629.csv